{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda1cd2d0d6e41a416eb3bb8aebfedc92b4",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import shutil \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    isExists = os.path.exists(path) \n",
    "    if not isExists:\n",
    "        os.makedirs(path)\n",
    "        return\n",
    "    else:\n",
    "        shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data_C(data, C):\n",
    "    data_with_c = data.copy()\n",
    "    data_with_c['C'] = C\n",
    "    return data_with_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nor_data(data2, method):\n",
    "    if method == 0:\n",
    "        return (data2 - data2.min())/(data2.max() - data2.min()) ##rescaling\n",
    "    if method == 1:\n",
    "        return (data2 - data2.mean())/(data2.max() - data2.min()) ##mean normalization\n",
    "    if method == 2:\n",
    "        return (data2-data2.mean())/(data2.std()) ##standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_group(inputfile, clusternumber, plotpath = \"./outplot\", method = 2, groupkey = \"indtype\", outcsvpath = \"./outcsv/\", SaveEachPlot = False):\n",
    "    ###\n",
    "    # 1. Read data as dataframe ###\n",
    "    #\n",
    "    data = pd.read_csv(inputfile)\n",
    "\n",
    "    ###\n",
    "    # 2.Grouped with keyvalue ###\n",
    "    #\n",
    "    data_to_count = data['indtype']\n",
    "    intdic = {}\n",
    "    for i in data_to_count: #count appe time\n",
    "        cur_key = int(i/100)\n",
    "        if cur_key in intdic:\n",
    "            if i in intdic[cur_key]:\n",
    "                intdic[cur_key][i] += 1\n",
    "            else:\n",
    "                intdic[cur_key][i] = 1\n",
    "        else:\n",
    "            intdic[cur_key] = {i:1}\n",
    "\n",
    "    del_list = []\n",
    "    count_dic = {}\n",
    "    for i in intdic:\n",
    "        summ = 0\n",
    "        for j in intdic[i]:\n",
    "            summ += intdic[i][j]\n",
    "        if summ < clusternumber:\n",
    "            del_list.append(i)\n",
    "        else:\n",
    "            count_dic[i] = summ\n",
    "\n",
    "    ##drop small group\n",
    "    for i in del_list:\n",
    "        del intdic[i]\n",
    "\n",
    "    order_dickey = list(intdic.keys())\n",
    "    order_dickey.sort()\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # 5. Data Process\n",
    "    pdfpath = inputfile + \"_group_xx\"+\"_c\" + str(clusternumber)  + \".pdf\"\n",
    "    data_feature = [] ##[group, giovsaled, perseng, voexpg, expinten, fa, ave_cwp]\n",
    "    with PdfPages(pdfpath) as pdf:\n",
    "        for i in order_dickey:\n",
    "            avail_keygroup = list(intdic[i].keys())\n",
    "            avail_keygroup.sort()\n",
    "            data_to_processed = data[data['indtype'] == avail_keygroup[0]]\n",
    "            for j in avail_keygroup[1:]:\n",
    "                df2 = data[data['indtype'] == j]\n",
    "                data_to_processed = data_to_processed.append(df2)\n",
    "\n",
    "            data_to_processed['ave_cwp'] = data_to_processed['cwp'] / data_to_processed['perseng']\n",
    "\n",
    "            ##5.2\n",
    "            data2 = pd.DataFrame(data_to_processed, columns = ['rndinten', 'expinten'])\n",
    "            ss = StandardScaler()\n",
    "            data2 = ss.fit_transform(data2)\n",
    "\n",
    "            ##5.3\n",
    "            sk_kmeans = KMeans(n_clusters=clusternumber)\n",
    "            sk_kmeans.fit(data2)\n",
    "\n",
    "            ##5.4produce cluster label\n",
    "            sk_C = sk_kmeans.predict(data2)\n",
    "            data_with_c = combine_data_C(data_to_processed, sk_C)\n",
    "\n",
    "            ##5.5 Save Plot\n",
    "            sns.lmplot('rndinten', 'expinten', hue='C', data=data_with_c, fit_reg=False)\n",
    "            plt.title(\"indtype = \"+str(i)+\"xx\")\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            if (SaveEachPlot):\n",
    "                plt.savefig(plotpath + str(intkey)+\".png\", dpi = 200)\n",
    "            plt.close()\n",
    "    \n",
    "            df1 = data_with_c[data_with_c['C'] == 0 ]\n",
    "            df2 = data_with_c[data_with_c['C'] == 1 ]\n",
    "\n",
    "            data_feature.append([str(i)+'xx','c0',df1['giovsaled'].mean(), df1['perseng'].mean(), df1['voexpg'].mean(), \n",
    "                                df1['expinten'].mean(), df1['fa'].mean(), df1['ave_cwp'].mean()])\n",
    "            \n",
    "            data_feature.append([str(i)+'xx','c1',df2['giovsaled'].mean(), df2['perseng'].mean(), df2['voexpg'].mean(), \n",
    "                                df2['expinten'].mean(), df2['fa'].mean(), df2['ave_cwp'].mean()])\n",
    "            \n",
    "            \n",
    "\n",
    "    d_feature = pd.DataFrame(data_feature, columns = ['group', 'class','ave_giovsaled', 'ave_perseng', 'ave_voexpg', 'ave_expinten', 'ave_fa', 'ave_cwp'])\n",
    "    d_feature.to_csv('data_feature.csv', index = 0)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"2001_big.csv\"\n",
    "num = 2\n",
    "csv_group(infile, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add .\n",
    "! git commit -m \"2.3update1\"\n",
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}